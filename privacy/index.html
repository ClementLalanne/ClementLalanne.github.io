---
layout: default
title: Privacy
---

<h2> Privacy </h2>

<h3> An Introduction to Differential Privacy </h3>

<h4> Lecture 1: </h4>
Basic definitions, properties and examples.
<a target="PDF" href="pres1_main.pdf"></a>, <a target="Slides" href="pres1_beamer.pdf"></a>.

<h3> Bibliography on Privacy</h3>

<h4> Differential privacy </h4>

<h5> Definitions </h5>

<a target="_blank" href="https://link.springer.com/chapter/10.1007/11681878_14">Calibrating Noise to Sensitivity in Private Data Analysis, Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam Smith, 2006</a>:
First definition of pure differential privacy.
<br/>
<a target="_blank" href="https://link.springer.com/chapter/10.1007/11761679_29">Our Data, Ourselves: Privacy Via DistributedNoise Generation, Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, Moni Naor, 2006</a>:
First definition of approximate differential privacy.
<br/>
<a target="_blank" href="https://arxiv.org/abs/1702.07476">Renyi Differential Privacy, Ilya Mironov, 2017</a>:
Definition of privacy that uses Renyi divergence and aims at simplifying the analysis of the tail of 
the privacy loss.
<br/>
<a target="_blank" href="https://arxiv.org/abs/1905.02383">Gaussian Differential Privacy, Jinshuo Dong, Aaron Roth, Weijie J. Su, 2019</a>:
Definition of privacy in term of testing difficulty. Allows tighter control than the previous ones. Comes with a composition theorem and 
a limit theorem.

<h5> Beyond global sensitivity </h5>

<a target="_blank" href="http://www.stat.cmu.edu/~jinglei/dprs_stoc09.pdf">Differential Privacy and Robust Statistics, Cynthia Dwork, Jing Lei, 2008</a>:
Presents the links between differential privacy and robust statistics. Based on this idea, it presents the Propose Test Release framework 
that allows to release information with a smaller noise than proportional to the global sensitivity. It has a probability to halt 
that is small if the permormed statistic is robust.
<br/>
<a target="_blank" href="https://cs-people.bu.edu/ads22//pubs/NRS07/NRS07-full-draft-v1.pdf">Smooth Sensitivity and Sampling in Private Data Analysis, Kobbi Nissim, Sofya Raskhodnikova, Adam Smith, 2011</a>:
Presents a way to release statistics with noise proportionnal to a smoothed local sensitivity. Studies also the sample and agregate mechanism and uses it 
to develop a differentially private k-means.
<br/>
<a target="_blank" href="https://arxiv.org/abs/2002.08774">Propose, Test, Release: Differentially private estimation with high probability, Victor-Emmanuel Brunel, Marco Avella-Medina, 2020</a>:
A development on the initial PTR algorithm.

<h5> Composition theorems </h5>

<a target="_blank" href="https://link.springer.com/chapter/10.1007/11681878_14">Calibrating Noise to Sensitivity in Private Data Analysis, Cynthia Dwork, Frank McSherry, Kobbi Nissim, Adam Smith, 2006</a>:
First composition theorem for pure differential privacy: "The epsilons add up".
<br/>
<a target="_blank" href="https://link.springer.com/chapter/10.1007/11761679_29">Our Data, Ourselves: Privacy Via DistributedNoise Generation, Cynthia Dwork, Krishnaram Kenthapadi, Frank McSherry, Ilya Mironov, Moni Naor, 2006</a>:
First composition theorem for approximate differential privacy: "The epsilons and deltas add up".
<br/>
<a target="_blank" href="https://people.seas.harvard.edu/~salil/research/PrivateBoosting-focs.pdf">Boosting and Differential Privacy, Cynthia Dwork, Guy N. Rothblum, Salil Vadhan, 2010</a>:
Tighter upper bound for the privacy of a composition of mechanisms.
<br/>
<a target="_blank" href="https://arxiv.org/abs/1311.0776">The Composition Theorem for Differential Privacy, Peter Kairouz, Sewoong Oh, Pramod Viswanath, 2015</a>:
Improvement of the previous bound for a new one that is proven tight.
<br/>

<h5> Empirical risk minimization </h5>

<a target="_blank" href="https://arxiv.org/abs/0912.0071">Differentially Private Empirical Risk Minimization, Kamalika Chaudhuri, Claire Monteleoni, Anand D. Sarwate, 2011</a>
<br/>
<a target="_blank" href="https://etda.libraries.psu.edu/catalog/16390">Differentially Private Convex Optimization For Empirical Risk Minimization And High-dimensional Regression, Guha Thakurta, Abhradeep, 2012</a>
<br/>
<a target="_blank" href="https://www.researchgate.net/profile/Xi_Wu19/publication/303993228_Differentially_Private_Stochastic_Gradient_Descent_for_in-RDBMS_Analytics/links/5772c5ff08ae07e45db2447d/Differentially-Private-Stochastic-Gradient-Descent-for-in-RDBMS-Analytics.pdf">Differentially Private Stochastic Gradient Descentfor in-RDBMS Analytics, Wu et al., 2016</a>
<br/>
<a target="_blank" href="https://arxiv.org/abs/1607.00133">Deep Learning with Differential Privacy, Martín Abadi, Andy Chu, Ian Goodfellow, H. Brendan McMahan, Ilya Mironov, Kunal Talwar, Li Zhang, 2016</a>

<h5> Others </h5>

<a target="_blank" href="https://arxiv.org/abs/0907.3754">On the Geometry of Differential Privacy, Moritz Hardt, Kunal Talwar, 2009</a>
<br/>
<a target="_blank" href="https://www.tau.ac.il/~saharon/BigData2015/privacybook.pdf">The Algorithmic Foundations of Differential Privacy, Cynthia Dwork, Aaron Roth, 2014</a>:
A good introduction to differential privacy. Doesn't take into account the state of the art since the field has evolved a lot in the recent years.
<br/>
<a target="_blank" href="https://arxiv.org/abs/1710.00901">Prochlo: Strong Privacy for Analytics in the Crowd, Bittau et al., 2017</a>:


<h4> General privacy </h4>

<h5> (Social) Graph privacy </h5>

<h5> Fingerprinting </h5>

<h5> Acoustic Cross-Device Tracking </h5>

<a target="_blank" href="https://caslab.csl.yale.edu/publications/matyunin2018zeropermission.pdf">Zero-Permission Acoustic Cross-Device Tracking, Nikolay Matyunin, Jakub Szefer, Stefan Katzenbeisser, 2018</a>: 
Presents how to perform acoustic cross-device tracking using gyroscopic sensor perturbation with ultrasonic sounds. At the time of the paper, 
applications did not need user's permission to access sensors like gyroscopes.
<br/>

<h5> Contact Tracing </h5>
<a target="_blank" href="https://hal.inria.fr/hal-02611265/document">ROBERT: ROBust and privacy-presERving proximityTracing, Claude Castelluccia, Nataliia Bielova, Antoine Boutet, Mathieu Cunche,Cédric Lauradoux, Daniel Le Métayer, Vincent Roca, 2019</a>:
Push/Pull approach of contact tracing with no linkage memory approach of contact tracing. This is the technology used by the french "Tous Anti Covid" app.
It doesn't use Apple or Google API's and hence works on Android phones without Google Play services. 
<br/>

<h4> Historical attacks </h4>

<h4> Other privacy-oriented resources </h4>

<a target="_blank" href="https://desfontain.es/privacy/">Damien Desfontaines' blog</a>: 
Google engineer and PhD student at the ETH Zürich who works and writes a blog 
on differential privacy.
<br/>
<a target="_blank" href="https://www.eff.org/">Electronic Frontier Foundation</a>:
"The leading nonprofit defending digital privacy, free speech, and innovation" according to their own words.
<br/>
<a target="_blank" href="https://www.youtube.com/channel/UCs6KfncB4OV6Vug4o_bzijg">Techlore's</a> and 
<a target="_blank" href="https://www.youtube.com/channel/UCjr2bPAyPV7t35MvcgT3W8Q">The Hated One's</a>:
Two youtube channels that cover privacy, security and FOSS news and present some user-friendly 
privacy-preserving tools.

<br/>
